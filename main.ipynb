{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Canceled bookings at a hotel</center></h1>\n",
    "\n",
    "\n",
    "You have been assigned the task of building a model that will predict whether or not a customer of a hotel will cancel their booking. The data for this assingment is found in the csv file `hotel_clf`\n",
    "\n",
    "<br> \n",
    "<div>\n",
    "<img src=\"https://5.imimg.com/data5/PC/BL/MY-33192851/hotel-reservation-services-500x500.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "<br> \n",
    "If the model predicts that a customer will cancel their booking, that customer will be sent a special deal to try to keep the customer from cancel the booking. If the prediction is correct (a True Positive), the expected gain is 1000 SEK. However, if the prediction is wrong (a False Positive), the expected loss is 500 SEK. \n",
    "\n",
    "Your goal is to build the most profitable model possible.\n",
    "\n",
    "<hr style=\"border:1px solid pink\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML imports\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Training \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Early stop to save time\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Evaluate models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 | Choose Metric\n",
    "\n",
    "Reason about which metric you think will be best to optimize your model for.\n",
    "\n",
    "- Recall?\n",
    "- Precision?\n",
    "- Accuracy?\n",
    "- F1-score?\n",
    "\n",
    "Make a decision about which metric you think will lead to the most profitable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer: I believe precision will lead to the most profitable model as it meassures\n",
    "the proportion of true positives out of all predicted positives.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 | Data prepatation\n",
    "\n",
    "- Prepare your data so that you end up with a clean and preprocessed train and test set\n",
    "    \n",
    "    \n",
    "- Instructions for train test split:    \n",
    "    - Test size = 0.2\n",
    "    - Random state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/hotel_clf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   hotel               10000 non-null  object \n",
      " 1   is_canceled         10000 non-null  int64  \n",
      " 2   lead_time           10000 non-null  int64  \n",
      " 3   adults              10000 non-null  int64  \n",
      " 4   children            10000 non-null  int64  \n",
      " 5   market_segment      10000 non-null  object \n",
      " 6   country             10000 non-null  object \n",
      " 7   reserved_room_type  10000 non-null  object \n",
      " 8   booking_changes     10000 non-null  int64  \n",
      " 9   adr                 10000 non-null  float64\n",
      " 10  customer_type       10000 non-null  object \n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City Hotel', 'Resort Hotel'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hotel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode hotel column\n",
    "data = pd.get_dummies(data, columns=['hotel'], prefix='hotel', drop_first=True) # drop first = true to avoid dummy trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Online TA', 'Offline TA/TO', 'Groups', 'Corporate', 'Direct',\n",
       "       'Complementary', 'Aviation'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['market_segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Market_segment column\n",
    "data = pd.get_dummies(data, columns=['market_segment'], prefix='segment', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ESP', 'FRA', 'PRT', 'DEU', 'DNK', 'GBR', 'AUT', 'USA', 'POL',\n",
       "       'NLD', 'BRA', 'GRC', 'TUR', 'SWE', 'ITA', 'BEL', 'IND', 'CHE',\n",
       "       'HRV', 'MYS', 'NOR', 'CHN', 'JPN', 'CN', 'ISR', 'LUX', 'IRL',\n",
       "       'HUN', 'ROU', 'IRQ', 'AGO', 'NGA', 'IRN', 'CZE', 'AUS', 'FIN',\n",
       "       'ARG', 'SGP', 'KOR', 'CYP', 'THA', 'PHL', 'LBN', 'TWN', 'SVN',\n",
       "       'UKR', 'SRB', 'COL', 'BGR', 'NZL', 'CHL', 'KEN', 'LVA', 'MAR',\n",
       "       'RUS', 'LTU', 'ALB', 'SAU', 'ARM', 'UZB', 'MEX', 'DZA', 'VEN',\n",
       "       'IDN', 'BIH', 'ECU', 'ZAF', 'TUN', 'URY', 'AND', 'BGD', 'MOZ',\n",
       "       'EGY', 'GEO', 'PAN', 'PAK', 'CPV', 'EST', 'ISL', 'PER', 'MUS',\n",
       "       'GIB', 'TJK', 'CIV', 'GNB', 'AZE', 'ARE', 'GUY', 'GGY', 'SVK',\n",
       "       'OMN', 'HKG', 'ZMB', 'BLR', 'CRI', 'MNE', 'BHR', 'MLT', 'MDV',\n",
       "       'CUB', 'GAB', 'LIE', 'LAO', 'BRB'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode country based on region to reduce the number of unique values\n",
    "# Create a dictionary for grouping countries into regions\n",
    "country_to_region = {\n",
    "    'ESP': 'Europe', 'FRA': 'Europe', 'PRT': 'Europe', 'DEU': 'Europe',\n",
    "    'DNK': 'Europe', 'GBR': 'Europe', 'AUT': 'Europe', 'POL': 'Europe',\n",
    "    'NLD': 'Europe', 'BEL': 'Europe', 'CHE': 'Europe', 'ITA': 'Europe',\n",
    "    'SWE': 'Europe', 'FIN': 'Europe', 'NOR': 'Europe', 'IRL': 'Europe',\n",
    "    'CZE': 'Europe', 'HUN': 'Europe', 'SVK': 'Europe', 'SVN': 'Europe',\n",
    "    'LUX': 'Europe', 'LTU': 'Europe', 'LVA': 'Europe', 'EST': 'Europe',\n",
    "    'ALB': 'Europe', 'BIH': 'Europe', 'HRV': 'Europe', 'MNE': 'Europe',\n",
    "    'SRB': 'Europe', 'GRC': 'Europe', 'CYP': 'Europe', 'ISL': 'Europe',\n",
    "    \n",
    "    'USA': 'Americas', 'BRA': 'Americas', 'CAN': 'Americas', 'ARG': 'Americas',\n",
    "    'MEX': 'Americas', 'COL': 'Americas', 'CHL': 'Americas', 'PER': 'Americas',\n",
    "    'URY': 'Americas', 'ECU': 'Americas', 'PAN': 'Americas', 'VEN': 'Americas',\n",
    "    'CRI': 'Americas', 'CUB': 'Americas', 'GUY': 'Americas',\n",
    "\n",
    "    'IND': 'Asia', 'CHN': 'Asia', 'JPN': 'Asia', 'KOR': 'Asia', 'THA': 'Asia',\n",
    "    'PHL': 'Asia', 'MYS': 'Asia', 'SGP': 'Asia', 'TWN': 'Asia', 'HKG': 'Asia',\n",
    "    'ARE': 'Asia', 'IRQ': 'Asia', 'IRN': 'Asia', 'UZB': 'Asia', 'TJK': 'Asia',\n",
    "    'PAK': 'Asia', 'BGD': 'Asia', 'MDV': 'Asia', 'KAZ': 'Asia', 'LKA': 'Asia',\n",
    "\n",
    "    'ZAF': 'Africa', 'KEN': 'Africa', 'DZA': 'Africa', 'NGA': 'Africa', \n",
    "    'MAR': 'Africa', 'EGY': 'Africa', 'MOZ': 'Africa', 'GHA': 'Africa',\n",
    "    'AGO': 'Africa', 'CIV': 'Africa', 'TUN': 'Africa', 'ZMB': 'Africa',\n",
    "\n",
    "    'AUS': 'Oceania', 'NZL': 'Oceania', 'FJI': 'Oceania', 'WSM': 'Oceania'\n",
    "}\n",
    "\n",
    "# Map countries to regions\n",
    "data['region'] = data['country'].map(country_to_region)\n",
    "\n",
    "# One-hot encode the region column\n",
    "data = pd.get_dummies(data, columns=['region'], prefix='region', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'D', 'B', 'C', 'L', 'E', 'G', 'F', 'H'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reserved_room_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode reserved_room_type\n",
    "# One-hot encode the reserved_room_type column\n",
    "data = pd.get_dummies(data, columns=['reserved_room_type'], prefix='room', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Transient', 'Transient-Party', 'Contract', 'Group'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['customer_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode customer_type\n",
    "# One-hot encode the customer_type column\n",
    "data = pd.get_dummies(data, columns=['customer_type'], prefix='type', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   is_canceled            10000 non-null  int64  \n",
      " 1   lead_time              10000 non-null  int64  \n",
      " 2   adults                 10000 non-null  int64  \n",
      " 3   children               10000 non-null  int64  \n",
      " 4   booking_changes        10000 non-null  int64  \n",
      " 5   adr                    10000 non-null  float64\n",
      " 6   hotel_Resort Hotel     10000 non-null  bool   \n",
      " 7   segment_Complementary  10000 non-null  bool   \n",
      " 8   segment_Corporate      10000 non-null  bool   \n",
      " 9   segment_Direct         10000 non-null  bool   \n",
      " 10  segment_Groups         10000 non-null  bool   \n",
      " 11  segment_Offline TA/TO  10000 non-null  bool   \n",
      " 12  segment_Online TA      10000 non-null  bool   \n",
      " 13  region_Americas        10000 non-null  bool   \n",
      " 14  region_Asia            10000 non-null  bool   \n",
      " 15  region_Europe          10000 non-null  bool   \n",
      " 16  region_Oceania         10000 non-null  bool   \n",
      " 17  room_B                 10000 non-null  bool   \n",
      " 18  room_C                 10000 non-null  bool   \n",
      " 19  room_D                 10000 non-null  bool   \n",
      " 20  room_E                 10000 non-null  bool   \n",
      " 21  room_F                 10000 non-null  bool   \n",
      " 22  room_G                 10000 non-null  bool   \n",
      " 23  room_H                 10000 non-null  bool   \n",
      " 24  room_L                 10000 non-null  bool   \n",
      " 25  type_Group             10000 non-null  bool   \n",
      " 26  type_Transient         10000 non-null  bool   \n",
      " 27  type_Transient-Party   10000 non-null  bool   \n",
      "dtypes: bool(22), float64(1), int64(5)\n",
      "memory usage: 683.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (8000, 27)\n",
      "Test Features Shape: (2000, 27)\n",
      "Training Labels Shape: (8000,)\n",
      "Test Labels Shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Now that the data is ready, I'll split it into train and test\n",
    "# Separate Features and Target Variable\n",
    "X = data.drop(columns=['is_canceled']) \n",
    "y = data['is_canceled']\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of training and test data\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Test Features Shape:\", X_test.shape)\n",
    "print(\"Training Labels Shape:\", y_train.shape)\n",
    "print(\"Test Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 | Build a LogReg Model\n",
    "\n",
    "Guidelines:\n",
    "- Use a LogisticRegression model\n",
    "    - Random state = 42\n",
    "- Use the metric you decided on in the previous question\n",
    "\n",
    "- You are not allowed to change the model after looking at the performance on test data\n",
    "- Your models predictions on test data will be translated into SEK. I.e:\n",
    "    - 10 TP = 10 * 1 000 SEK = +10 000 \n",
    "    - 10 FP = 10 * -500 SEK = -5 000 SEK\n",
    "        - Expected Value from model = +5 000 SEK \n",
    "        \n",
    "        \n",
    "After you have trained your model, make predictions for your test data and calculate the profitable of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7345\n",
      "Confusion Matrix:\n",
      "[[1116  124]\n",
      " [ 417  343]]\n",
      "Total Profit: 281000 SEK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression Model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate precision to evaluate performance\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Unpacking the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate profits\n",
    "profit_tp = tp * 1000  # Each TP gives 1000 SEK\n",
    "profit_fp = fp * -500  # Each FP costs 500 SEK\n",
    "\n",
    "total_profit = profit_tp + profit_fp\n",
    "print(f\"Total Profit: {total_profit} SEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 | Build a RandomForestClassifier model\n",
    "\n",
    "- Use a RandomForestClassifier model:\n",
    "    - random_state = 42\n",
    "\n",
    "\n",
    "- After you have trained your model, make predictions for your test data and calculate the profitable of the model\n",
    "\n",
    "- Which model was more profitable, the LogReg or the RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Precision: 0.7193\n",
      "RandomForest Confusion Matrix:\n",
      "[[1055  185]\n",
      " [ 286  474]]\n",
      "RandomForest Total Profit: 381500 SEK\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Train RandomForestClassifier Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate precision for RandomForestClassifier\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "print(f\"RandomForest Precision: {precision_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix for RandomForest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"RandomForest Confusion Matrix:\")\n",
    "print(cm_rf)\n",
    "\n",
    "# Unpacking the confusion matrix for RandomForest\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = cm_rf.ravel()\n",
    "\n",
    "# Calculate profits for RandomForest\n",
    "profit_tp_rf = tp_rf * 1000  # Each TP gives 1000 SEK\n",
    "profit_fp_rf = fp_rf * -500  # Each FP costs 500 SEK\n",
    "total_profit_rf = profit_tp_rf + profit_fp_rf\n",
    "print(f\"RandomForest Total Profit: {total_profit_rf} SEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would seem that logistic regression is more profitable according to the metric I chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 | Did you choose the right metric? \n",
    "\n",
    "Calculate the profitablity for the RandomForestClassifier for all 4 different metrics. Then rank order the outcome. I.e.:\n",
    "\n",
    "- RFC (precision) = 1\n",
    "- RFC (accuracy) = 2\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "\n",
    "***Note:*** You don't have to use a param_grid for this question, just run the RandomForest with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Profits:\n",
      "RFC (Accuracy) = 1 with Profit: 1293500 SEK\n",
      "RFC (Precision) = 2 with Profit: 381500 SEK\n",
      "RFC (Recall) = 3 with Profit: 381500 SEK\n",
      "RFC (F1-score) = 4 with Profit: 381500 SEK\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Train RandomForestClassifier Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix for RandomForest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = cm_rf.ravel()\n",
    "\n",
    "# Profit calculation based on the confusion matrix\n",
    "def calculate_profit(tp, fp, fn, tn=None):\n",
    "    profit_tp = tp * 1000  # Each TP gives 1000 SEK\n",
    "    profit_fp = fp * -500  # Each FP costs 500 SEK\n",
    "    return profit_tp + profit_fp\n",
    "\n",
    "# Calculate profit for each metric\n",
    "# Precision Profit\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "precision_profit = calculate_profit(tp_rf, fp_rf, fn_rf)\n",
    "\n",
    "# Accuracy Profit (using all metrics TP, TN, FP, FN)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_profit = (tp_rf + tn_rf) * 1000 + fp_rf * -500 + fn_rf * -500\n",
    "\n",
    "# Recall Profit\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "recall_profit = calculate_profit(tp_rf, fp_rf, fn_rf)\n",
    "\n",
    "# F1-score Profit\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "f1_profit = calculate_profit(tp_rf, fp_rf, fn_rf)\n",
    "\n",
    "# Rank the profitability based on each metric\n",
    "profits = {\n",
    "    \"Precision\": precision_profit,\n",
    "    \"Accuracy\": accuracy_profit,\n",
    "    \"Recall\": recall_profit,\n",
    "    \"F1-score\": f1_profit\n",
    "}\n",
    "\n",
    "# Rank the models by profitability\n",
    "ranked_metrics = sorted(profits.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display Results\n",
    "print(f\"RandomForest Profits:\")\n",
    "for i, (metric, profit) in enumerate(ranked_metrics, start=1):\n",
    "    print(f\"RFC ({metric}) = {i} with Profit: {profit} SEK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
